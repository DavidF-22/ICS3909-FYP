{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras as k\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import encoder.binding_2D_matrix_encoder as b2d_encoder\n",
    "\n",
    "\n",
    "\n",
    "# parameters\n",
    "training_file_path = '../datasets/training/AGO2_CLASH_Hejret2023_TRAIN.tsv'\n",
    "testing_file_path = '../datasets/testing/AGO2_CLASH_Hejret2023_TEST.tsv'\n",
    "alphabet = {\"AT\": 1., \"TA\": 1., \"GC\": 1., \"CG\": 1., \"AU\": 1., \"UA\": 1.}\n",
    "input_shape = (50, 20, 1)  # shape of the input image\n",
    "learning_rate = 0.001  # learning rate\n",
    "epochs = 20  # number of epochs/dataset iterations\n",
    "batch_size = 32  # batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResBlock Class and Building ResNet function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a custom Keras layer which inturn implements a residual block\n",
    "@register_keras_serializable()\n",
    "class ResBlock(layers.Layer):\n",
    "    \"\"\"\n",
    "    Defines a Residual block based on the original ResNet paper.\n",
    "    The block either maintains the input dimensions or downsamples based on the specified parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, downsample=False, filters=16, kernel_size=3):\n",
    "        \"\"\"\n",
    "        Initializes the residual block with optional downsampling.\n",
    "        \n",
    "        Parameters:\n",
    "        - downsample: Boolean, whether to downsample the input (using stride of 2)\n",
    "        - filters: Number of filters for the Conv2D layers\n",
    "        - kernel_size: Size of the convolution kernel\n",
    "        \"\"\"\n",
    "        # calling the parent class constructor\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        # parameters for the residual block\n",
    "        self.downsample = downsample\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # initialize first convolution layer, with stride 1 or 2 depending on downsampling\n",
    "        self.conv1 = layers.Conv2D(kernel_size=self.kernel_size,\n",
    "                                   strides=(1 if not self.downsample else 2),\n",
    "                                   filters=self.filters,\n",
    "                                   padding=\"same\")\n",
    "        self.activation1 = layers.ReLU()  # activation function after first convolution\n",
    "        self.batch_norm1 = layers.BatchNormalization()  # batch normalization after first convolution\n",
    "        \n",
    "        # initialize second convolution layer with stride 1 (no downsampling here)\n",
    "        self.conv2 = layers.Conv2D(kernel_size=self.kernel_size,\n",
    "                                   strides=1,\n",
    "                                   filters=self.filters,\n",
    "                                   padding=\"same\")\n",
    "\n",
    "        # third convolution if downsampling is needed to match input dimensions\n",
    "        if self.downsample:\n",
    "          self.conv3 = layers.Conv2D(kernel_size=1,\n",
    "                                     strides=2,\n",
    "                                     filters=self.filters,\n",
    "                                     padding=\"same\")\n",
    "\n",
    "        self.activation2 = layers.ReLU()  # activation after second convolution\n",
    "        self.batch_norm2 = layers.BatchNormalization()  # batch normalization after second convolution\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass for the residual block. Applies the convolutions, activation, and adds the skip connection.\n",
    "\n",
    "        Parameters:\n",
    "        - inputs: Input tensor\n",
    "\n",
    "        Returns:\n",
    "        - Tensor after applying the residual block transformation\n",
    "        \"\"\"\n",
    "        # first convolution, activation, and batch normalization\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.activation1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        \n",
    "        # second convolution (no downsampling here)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # adjust input dimensions if downsampling\n",
    "        if self.downsample:\n",
    "            inputs = self.conv3(inputs)\n",
    "\n",
    "        # add the input (skip connection) to the output of the convolutions\n",
    "        x = layers.Add()([inputs, x])\n",
    "\n",
    "        # final activation and batch normalization\n",
    "        x = self.activation2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Returns the configuration of the residual block (required for saving and loading the model).\n",
    "        \"\"\"\n",
    "        return {'filters': self.filters, 'downsample': self.downsample, 'kernel_size': self.kernel_size}\n",
    "    \n",
    "# define the ResNet model\n",
    "def build_resnet(input_shape):\n",
    "    \"\"\"\n",
    "    Builds a simple ResNet model using custom residual blocks.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # initial Conv Layer\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # add ResBlocks\n",
    "    x = ResBlock(filters=64, downsample=False)(x)\n",
    "    x = ResBlock(filters=64, downsample=False)(x)\n",
    "\n",
    "    # flatten and add dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)  # binary classification (0 or 1)\n",
    "\n",
    "    # build model\n",
    "    model = models.Model(inputs, x)\n",
    "    # compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    # output model summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Encoding and Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the data using your binding_2D_matrix_encoder's binding_encoding function\n",
    "def encode_dataset(data):\n",
    "    # use the function from the binding_2D_matrix_encoder module\n",
    "    return b2d_encoder.binding_encoding(data, alphabet=alphabet)\n",
    "\n",
    "# load the datasets\n",
    "print(\"----- <Loading Datasets> -----\")\n",
    "df_train = pd.read_csv(training_file_path, sep='\\t')\n",
    "df_test = pd.read_csv(testing_file_path, sep='\\t')\n",
    "print(\"----- <Datasets Loaded Successfully> -----\\n\")\n",
    "\n",
    "# print the dataset shape and first few rows\n",
    "print(f\"Training Dataset shape: {df_train.shape}\")\n",
    "print(f\"First few rows of the dataset:\\n{df_train.head()}\\n\")\n",
    "print(f\"Testing Dataset shape: {df_test.shape}\")\n",
    "print(f\"First few rows of the dataset:\\n{df_test.head()}\\n\")\n",
    "\n",
    "# Split df_train into actual training and validation sets\n",
    "training_data, validation_data = train_test_split(df_train, test_size=0.1, random_state=42)\n",
    "print(f\"Size of training set: {len(training_data)}\")\n",
    "print(f\"Size of validation set: {len(validation_data)}\\n\")\n",
    "\n",
    "# encode the training data and testing data\n",
    "print(\"----- <Encoding Data> -----\")\n",
    "encoded_training_data, training_labels = encode_dataset(training_data)\n",
    "encoded_validation_data, validation_labels = encode_dataset(validation_data)\n",
    "encoded_testing_data, testing_labels = encode_dataset(df_test)\n",
    "# print completion message example of encoded data\n",
    "print(\"----- <Data Encoded Successfully> -----\\n\")\n",
    "'''Displaying the encoded data'''\n",
    "# print(f\"Encoded training data shape: {encoded_training_data.shape}\")\n",
    "# print(f\"Encoded validation data shape: {encoded_validation_data.shape}\\n\")\n",
    "# print(f\"Encoded testing data shape: {encoded_testing_data.shape}\")\n",
    "# print(f\"First encoded training example:\\n{encoded_training_data[0]}\")\n",
    "# print(f\"First training label: {training_labels[0]}\\n\")\n",
    "# print(f\"First encoded testing example:\\n{encoded_testing_data[0]}\")\n",
    "\n",
    "# build the ResNet model\n",
    "input_shape = encoded_training_data.shape[1:]  # assuming the encoded data is 4D (samples, height, width, channels)\n",
    "print(\"----- <Building Model> -----\")\n",
    "model = build_resnet(input_shape)\n",
    "print(\"----- <Model Built Successfully> -----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "print(\"----- <Training Model> -----\")\n",
    "history = model.fit(encoded_training_data, training_labels, epochs=epochs, batch_size=batch_size, \n",
    "                    validation_data=(encoded_validation_data, validation_labels))\n",
    "print(\"----- <Model Trained Successfully> -----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting training and validation accuracy and loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.axis(ymin=0.4, ymax=1)\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train_Accuracy', 'Validation_Accuracy'])\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "\n",
    "# plotting loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train_Loss', 'Validation_Loss'])\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "print(\"----- <Evaluating Model> -----\")\n",
    "test_loss, test_accuracy = model.evaluate(encoded_testing_data, testing_labels)\n",
    "print(\"----- <Model Evaluated Successfully> -----\\n\")\n",
    "print(f\"Test loss: {round(test_loss, 4)} - {round(test_loss, 4) * 100}%\\nTest accuracy: {round(test_accuracy, 4)} - {round(test_accuracy, 4) * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "print(\"----- <Saving Model> -----\")\n",
    "model.save(\"miRBind_ResNet.keras\")\n",
    "print(\"----- <Model Saved Successfully> -----\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
